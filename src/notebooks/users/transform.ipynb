{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de430f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp, to_date, datediff, current_date, lit, concat_ws, year, floor, current_timestamp\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Initialize SparkSession if not already available\n",
    "spark = SparkSession.builder.appName(\"Users Transform\").getOrCreate()\n",
    "\n",
    "# Define Unity Catalog catalog and schema names\n",
    "# IMPORTANT: Replace 'your_catalog' and 'your_schema' with your actual desired Unity Catalog catalog and schema names.\n",
    "catalog_name = \"main_catalog\"\n",
    "schema_name = \"silver_users_schema\"\n",
    "\n",
    "# Create catalog and schema if they don't exist\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "# Define the Unity Catalog input and output table names\n",
    "input_table_name = \"main_catalog.bronze_users_schema.users_raw\"\n",
    "output_table_name = f\"{catalog_name}.{schema_name}.users_transformed\"\n",
    "\n",
    "# Read the raw data from the Unity Catalog table\n",
    "df = spark.read.table(input_table_name)\n",
    "\n",
    "# Perform transformations\n",
    "# Assuming the raw DataFrame 'df' has columns like:\n",
    "# user_id, first_name, last_name, email, date_of_birth, registration_date\n",
    "\n",
    "transformed_df = df.withColumn(\n",
    "    # 1. Create a full_name column\n",
    "    \"full_name\", concat_ws(\" \", col(\"first_name\"), col(\"last_name\"))\n",
    ").withColumn(\n",
    "    # 2. Convert string dates to proper date/timestamp types\n",
    "    \"registration_ts\", to_timestamp(\"registration_date\", \"yyyy-MM-dd HH:mm:ss\")\n",
    ").withColumn(\n",
    "    \"birth_date\", to_date(\"date_of_birth\", \"yyyy-MM-dd\")\n",
    ").withColumn(\n",
    "    # 3. Calculate user's current age\n",
    "    \"age\", floor(datediff(current_date(), col(\"birth_date\")) / 365.25)\n",
    ").withColumn(\n",
    "    # 4. Calculate user's tenure in days\n",
    "    \"days_as_member\", datediff(current_date(), col(\"registration_ts\"))\n",
    ").withColumn(\n",
    "    # 5. Add a metadata column for load timestamp\n",
    "    \"_load_timestamp\", current_timestamp()\n",
    ").select(\n",
    "    # 6. Select and reorder columns for the final silver table\n",
    "    col(\"user_id\"),\n",
    "    col(\"full_name\"),\n",
    "    col(\"email\"),\n",
    "    col(\"age\"),\n",
    "    col(\"days_as_member\"),\n",
    "    col(\"registration_ts\"),\n",
    "    col(\"_load_timestamp\")\n",
    ")\n",
    "\n",
    "# Write the transformed data to the Unity Catalog silver table\n",
    "transformed_df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(output_table_name)\n",
    "\n",
    "print(f\"Successfully transformed data and saved to {output_table_name}\")\n",
    "\n",
    "# Display a sample of the transformed data\n",
    "display(spark.read.table(output_table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee08019",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
