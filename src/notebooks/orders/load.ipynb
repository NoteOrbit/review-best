{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Databricks notebook source\n",
        "\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "# --- Unity Catalog Configuration ---",
        "catalog_name = \"main_catalog\"",
        "schema_name = \"etl_demo\"",
        "input_table_name = \"orders_transformed\"",
        "output_table_name = \"orders\" # Final table name\n",
        "\n",
        "# Use the catalog and schema",
        "spark.sql(f\"USE CATALOG {catalog_name}\")",
        "spark.sql(f\"USE SCHEMA {schema_name}\")",
        "\n",
        "try:",
        